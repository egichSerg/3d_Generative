{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a63669e1-781e-456f-a6a1-881d0d12fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import img_as_ubyte\n",
    "from pytorch3d.io import load_obj\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.renderer import (\n",
    "FoVPerspectiveCameras, look_at_view_transform,\n",
    "look_at_rotation, RasterizationSettings,\n",
    "MeshRenderer, MeshRasterizer,\n",
    "BlendParams, SoftSilhouetteShader, HardPhongShader,\n",
    "PointLights, TexturesVertex,\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import imageio, PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef744bd8-c3d0-4ab0-b71d-0083dc1a3007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  149k  100  149k    0     0   165k      0 --:--:-- --:--:-- --:--:--  165k\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/PacktPublishing/3D-Deep-Learning-with-Python/refs/heads/main/chap4/data/teapot.obj -o ./data/teapot.obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f01b843-e0f8-4c2e-969e-5a8025ea9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc7372d-b5ba-4040-aea7-dde75b2ff4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('./data')\n",
    "output_dir = Path('./result_teapot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e08a1f-5698-4828-97d8-8a101a38141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/pytorch3d/io/obj_io.py:544: UserWarning: No mtl file provided\n",
      "  warnings.warn(\"No mtl file provided\")\n"
     ]
    }
   ],
   "source": [
    "verts, faces_idx, _ = load_obj(\"./data/teapot.obj\")\n",
    "faces = faces_idx.verts_idx\n",
    "\n",
    "verts_rgb = torch.ones_like(verts).unsqueeze(0)\n",
    "textures = TexturesVertex(verts_features=verts_rgb.to(device))\n",
    "\n",
    "teapot_mesh = Meshes(\n",
    "    verts=[verts.to(device)],\n",
    "    faces=[faces.to(device)],\n",
    "    textures=textures\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5355cda-da58-4079-897a-401533225b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = FoVPerspectiveCameras(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de0674d-bc71-4ac5-8171-d7c01c108e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_params = BlendParams(sigma=1e-4, gamma=1e-4)\n",
    "\n",
    "raster_settings = RasterizationSettings(\n",
    "    image_size = 256,\n",
    "    blur_radius = np.log(1. / 1e-4 - 1.) * blend_params.sigma,\n",
    "    faces_per_pixel = 100,\n",
    ")\n",
    "\n",
    "silhouette_renderer = MeshRenderer(\n",
    "    rasterizer = MeshRasterizer(\n",
    "        cameras=cameras,\n",
    "        raster_settings=raster_settings\n",
    "    ),\n",
    "    shader=SoftSilhouetteShader(blend_params=blend_params)\n",
    ")\n",
    "\n",
    "raster_settings = RasterizationSettings(\n",
    "        image_size=256,\n",
    "        blur_radius=0.0,\n",
    "        faces_per_pixel=1,\n",
    "    )\n",
    "\n",
    "lights = PointLights(\n",
    "        device=device,\n",
    "        location=((2.0, 2.0, -2.0),)\n",
    "    )\n",
    "\n",
    "phong_renderer = MeshRenderer(\n",
    "    rasterizer=MeshRasterizer(\n",
    "            cameras=cameras,\n",
    "            raster_settings=raster_settings\n",
    "        ),\n",
    "    shader=HardPhongShader(\n",
    "            device=device,\n",
    "            cameras=cameras,\n",
    "            lights=lights\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1871c92d-6983-4863-990f-47e8000a2e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = 3\n",
    "elevation = 50.0\n",
    "azimuth = 0.0\n",
    "R, T = look_at_view_transform(distance,\n",
    "    elevation,\n",
    "    azimuth,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4d5447c-843a-4f51-95b4-b84fa93eb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette = silhouette_renderer(meshes_world=teapot_mesh, R=R, T=T)\n",
    "image_ref = phong_renderer(meshes_world=teapot_mesh, R=R, T=T)\n",
    "\n",
    "silhouette = silhouette.cpu().numpy()\n",
    "image_ref = image_ref.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9ce4fb0-bd35-411c-9457-476677f93b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93e5c97e-a007-4751-9b34-581f9579efe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf6b80d6-e0a0-4eab-b2d1-e92c89d8774c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(image_ref[..., :3].max(-1) != 1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aa95865-c5c3-4209-915f-046afc0e7fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(silhouette[..., :3].max(-1) != 1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f47c00e-40ea-409e-b83a-039e02c711aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "# Рисовать только альфа-канал RGBA-изображения\n",
    "plt.imshow(silhouette.squeeze()[..., 3])\n",
    "plt.grid(False)\n",
    "plt.savefig(os.path.join(output_dir, 'target_silhouette.png'))\n",
    "plt.close()\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_ref.squeeze())\n",
    "plt.grid(False)\n",
    "plt.savefig(os.path.join(output_dir, 'target_rgb.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5ebf2de-4539-4923-859f-d05cd6ef6d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, meshes, renderer, image_ref):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.meshes = meshes\n",
    "        self.device = meshes.device\n",
    "        self.renderer = renderer\n",
    "\n",
    "        image_ref = torch.from_numpy(\n",
    "            (image_ref[..., :3].max(-1) != 1).astype(np.float32)\n",
    "        )\n",
    "\n",
    "        self.register_buffer('image_ref', image_ref)\n",
    "\n",
    "        self.camera_position = nn.Parameter(\n",
    "            torch.from_numpy(np.array([3.0, 6.9, +2.5], dtype=np.float32)).to(self.device)\n",
    "        )\n",
    "\n",
    "    def forward(self):\n",
    "        R = look_at_rotation(self.camera_position.unsqueeze(0), device=self.device)\n",
    "        T = -torch.bmm(\n",
    "            R.transpose(1, 2),\n",
    "            self.camera_position[None, :, None])[:, :, 0] # (1, 3)\n",
    "\n",
    "        image = self.renderer(meshes_world=self.meshes.clone(), R=R, T=T)\n",
    "        \n",
    "        loss = torch.sum((image[..., 3] - self.image_ref) ** 2) # per pixel MSE\n",
    "        \n",
    "        return loss, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1176a716-82e2-47a4-a426-9ad9eb5c8fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (renderer): MeshRenderer(\n",
       "    (rasterizer): MeshRasterizer(\n",
       "      (cameras): FoVPerspectiveCameras()\n",
       "    )\n",
       "    (shader): SoftSilhouetteShader()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(meshes=teapot_mesh,\n",
    "             renderer=silhouette_renderer,\n",
    "             image_ref=image_ref).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "322185de-ca6d-4e2d-a07f-510f9ab99f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03f87e6b-9f98-416e-9e29-fdd65b8fa466",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, image_init = model()\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_init.detach().squeeze().cpu().numpy()[..., 3])\n",
    "plt.grid(False)\n",
    "plt.title(\"Стартовый силуэт\")\n",
    "plt.savefig(os.path.join(output_dir, 'starting_silhouette.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4308e8cb-80b1-41f9-8146-da73d9cadb3e",
   "metadata": {},
   "source": [
    "### Ура ура оптимизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dafb3cb4-d71a-457f-9f93-390fe6e9b2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████████████████████████████████████                                                                                                                | 72/200 [00:03<00:07, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ВСЁ!\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "images = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "\n",
    "    loss, _ = model()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if loss.item() < 500:\n",
    "        print('ВСЁ!')\n",
    "        break\n",
    "\n",
    "    # render an image\n",
    "    R = look_at_rotation(model.camera_position[None, :], device=model.device)\n",
    "    T = -torch.bmm(R.transpose(1, 2), model.camera_position[None, :, None])[:, :, 0] # (1, 3)\n",
    "    image = phong_renderer(meshes_world=model.meshes.clone(), R=R, T=T)\n",
    "    image = image[0, ..., :3].detach().squeeze().cpu().numpy()\n",
    "    image = img_as_ubyte(image)\n",
    "    images.append(image)\n",
    "\n",
    "\n",
    "imageio.mimsave(output_dir / 'teapot.gif', images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
